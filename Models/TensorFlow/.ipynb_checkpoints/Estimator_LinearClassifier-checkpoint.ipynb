{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-015204212e1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import operator\n",
    "# Non pythonic hack to reuse some utility code\n",
    "if sys.path[0] != '../../py_utils':\n",
    "    sys.path.insert(0,'../../py_utils')\n",
    "\n",
    "import file_utils  \n",
    "import utils\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "print(\"Seaborn version: \", sns.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_team_file = '../../Data/sr_summaries_kaggle_id_no_opp_2018.csv'\n",
    "team_meta_data_file = '../../Data/D1_teams.csv'\n",
    "tournament_data_file = '../../Data/tournament_results_2018.csv'\n",
    "rankings_data_file = '../../data/massey_seasons_with_id.csv'\n",
    "\n",
    "feature_dictionary = utils.Feature_Dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not use 2018 data for training\n",
    "start_tournament = 2003\n",
    "stop_tournament = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in regular season team statistics from SRCBB https://www.sports-reference.com/cbb/\n",
    "\n",
    "#### Read table of team names and associated team meta data from the Kaggle data set.\n",
    "https://console.cloud.google.com/bigquery?project=bigqueryncaa&p=bigquery-public-data&d=ncaa_basketball&page=dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = file_utils.read_summary_team_data(summary_team_file)\n",
    "teams = file_utils.read_team_meta_data(team_meta_data_file)\n",
    "summary_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in the NCAA Men's Tournament results from the the Kaggle data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourney_data = file_utils.read_tournament_results(tournament_data_file,start_tournament)\n",
    "game_data = utils.compute_game_data(tourney_data, teams)\n",
    "computer_rankings = pd.read_csv(Path(rankings_data_file))\n",
    "computer_rankings = computer_rankings[computer_rankings['season'] >= start_tournament]\n",
    "\n",
    "tourney_data = utils.recode_tourney_data(tourney_data)\n",
    "tourney_data = file_utils.merge_tourney_summary_data(tourney_data, summary_data)\n",
    "tourney_data = file_utils.join_tourney_team_data(tourney_data, teams)\n",
    "tourney_comp_ratings = file_utils.merge_tourney_ranking_data(tourney_data, computer_rankings)\n",
    "tourney_comp_ratings = utils.implement_top_conference_feature(game_data, tourney_comp_ratings)\n",
    "tourney_comp_ratings = utils.implement_seed_threshold_feature(tourney_comp_ratings)\n",
    "tourney_comp_ratings = utils.compute_delta_features(tourney_comp_ratings)\n",
    "\n",
    "tourney_comp_ratings.dropna(inplace=True)\n",
    "tourney_comp_ratings[tourney_comp_ratings.isnull().any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping delta_rpi\n",
    "numeric_features = ['delta_margin_victory_avg', 'delta_fg_pct', 'delta_off_rebs_avg',\n",
    "                            'delta_def_rebs_avg', 'delta_ft_pct',\n",
    "                            'delta_to_net_avg', 'delta_win_pct', 'delta_off_rating',\n",
    "                            'delta_ft_att_avg',\n",
    "                            'delta_seed', 'delta_srs', 'delta_sos',\n",
    "                            'delta_sag', 'delta_wlk', 'delta_wol',\n",
    "                            'delta_rth', 'delta_col', 'delta_pom',\n",
    "                            'delta_dol', 'delta_mor']\n",
    "\n",
    "for item in numeric_features:\n",
    "    tourney_comp_ratings[item] = tourney_comp_ratings[item].astype(float)\n",
    "\n",
    "#scaler =StandardScaler()\n",
    "#tourney_comp_ratings[numeric_feature_to_scale] = scaler.fit_transform(tourney_comp_ratings[numeric_feature_to_scale])\n",
    "#tourney_comp_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = numeric_features  + ['season_t', 'top_conf_t', 'top_conf_o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data = tourney_comp_ratings[feature_columns].copy()\n",
    "#feature_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup feature columns for Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_top_conf_t = tf.feature_column.numeric_column('top_conf_t')\n",
    "tf_top_conf_o = tf.feature_column.numeric_column('top_conf_o')\n",
    "tf_margin_victory = tf.feature_column.numeric_column('delta_margin_victory_avg')\n",
    "tf_delta_fg = tf.feature_column.numeric_column('delta_fg_pct')\n",
    "tf_delta_off_rebs = tf.feature_column.numeric_column('delta_off_rebs_avg')\n",
    "tf_delta_def_rebs = tf.feature_column.numeric_column('delta_def_rebs_avg')\n",
    "tf_delta_ft = tf.feature_column.numeric_column('delta_ft_pct')\n",
    "tf_delta_to = tf.feature_column.numeric_column('delta_to_net_avg')\n",
    "tf_delta_win = tf.feature_column.numeric_column('delta_win_pct')\n",
    "tf_delta_off_rating = tf.feature_column.numeric_column('delta_off_rating')\n",
    "tf_delta_ft_att = tf.feature_column.numeric_column('delta_ft_att_avg')\n",
    "tf_delta_seed = tf.feature_column.numeric_column('delta_seed')\n",
    "tf_delta_srs = tf.feature_column.numeric_column('delta_srs')\n",
    "tf_delta_sos = tf.feature_column.numeric_column('delta_sos')\n",
    "tf_delta_sag = tf.feature_column.numeric_column('delta_sag')\n",
    "tf_delta_wlk = tf.feature_column.numeric_column('delta_wlk')\n",
    "tf_delta_wol = tf.feature_column.numeric_column('delta_wol')\n",
    "tf_delta_rth = tf.feature_column.numeric_column('delta_rth')\n",
    "tf_delta_col = tf.feature_column.numeric_column('delta_col')\n",
    "tf_delta_pom = tf.feature_column.numeric_column('delta_pom')\n",
    "tf_delta_dol = tf.feature_column.numeric_column('delta_dol')\n",
    "#tf_delta_rpi = tf.feature_column.numeric_column('delta_rpi')\n",
    "tf_delta_mor = tf.feature_column.numeric_column('delta_mor')\n",
    "\n",
    "# todo  drop tf_delta_rpi\n",
    "tf_feat_cols = [tf_margin_victory, tf_delta_fg, tf_delta_off_rebs, \n",
    "                tf_delta_def_rebs, tf_delta_ft, tf_delta_to, tf_delta_win, tf_delta_off_rating, \n",
    "                tf_delta_ft_att, tf_delta_seed, tf_delta_srs, tf_delta_sos, tf_delta_sag, \n",
    "                tf_delta_wlk, tf_delta_wol, tf_delta_rth, tf_delta_col, tf_delta_pom,\n",
    "                tf_delta_dol, tf_delta_mor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= feature_data[feature_data['season_t']<= stop_tournament]\n",
    "tourney_comp_ratings['label'] = tourney_comp_ratings.apply(lambda x: 0 if x.game_result==-1 else 1, axis=1)\n",
    "y=tourney_comp_ratings[tourney_comp_ratings['season_t']<= stop_tournament]['label']\n",
    "X= X.drop(columns=['season_t'])\n",
    "\n",
    "feature_list = list(X)\n",
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 5)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "\n",
    "scaler.fit(X_train[numeric_features])\n",
    "X_train[numeric_features] = scaler.transform(X_train[numeric_features])\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train, y=y_train, batch_size=50, num_epochs=None, shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.estimator.LinearClassifier(feature_columns= tf_feat_cols, n_classes=2)\n",
    "model.train(input_fn = input_func, steps=15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test, y=y_test, batch_size=50, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(eval_input_func)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify the predicted results for the test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test, batch_size=50, num_epochs=1, shuffle=False)\n",
    "predictions_test = model.predict(pred_input_func)\n",
    "test_predictions = list(predictions_test)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = [pred['class_ids'][0] for pred in test_predictions ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_df = y_test.to_frame('y_actual')\n",
    "y_test_df['y_predict'] = test_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_predictions = y_test_df[y_test_df['y_actual'] != y_test_df['y_predict']].copy()\n",
    "missed_predictions.reset_index(inplace=True)\n",
    "missed_predictions.rename({\"index\":\"sample_index\"}, axis='columns', inplace=True)\n",
    "missed_predictions = missed_predictions.sort_values(by=['sample_index'])\n",
    "len(missed_predictions.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_confusion_matrix(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_year = 2018\n",
    "X_season = feature_data[feature_data['season_t']== test_year]\n",
    "scaler.fit_transform(X_season[numeric_features])\n",
    "y_season = tourney_comp_ratings[tourney_comp_ratings['season_t']== test_year]['label']\n",
    "X_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2018_input_func = tf.estimator.inputs.pandas_input_fn(x=X_season, batch_size=10, num_epochs=1, shuffle=False)\n",
    "predictions_2018 = model.predict(pred_2018_input_func)\n",
    "pred_2018 = list(predictions_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_2018 = [pred['class_ids'][0] for pred in pred_2018 ]\n",
    "y_2018_df = y_season.to_frame('y_actual')\n",
    "y_2018_df['y_predict'] = preds_2018\n",
    "y_2018_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_win_probabilities = [pred['probabilities'][1] for pred in pred_2018 ]\n",
    "#t1_win_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_2018_predictions = y_2018_df[y_2018_df['y_actual'] != y_2018_df['y_predict']].copy()\n",
    "\n",
    "missed_2018_predictions.reset_index(inplace=True)\n",
    "missed_2018_predictions.rename({\"index\":\"sample_index\"}, axis='columns', inplace=True)\n",
    "missed_2018_predictions = missed_2018_predictions.sort_values(by=['sample_index'])\n",
    "#len(missed_2018_predictions.index)\n",
    "missed_2018_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.display_confusion_matrix(y_season, preds_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counter Seeding Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_zero_to_minus_one(x):\n",
    "    if x==0:\n",
    "        return -1\n",
    "    else:\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tourney_games = tourney_comp_ratings[tourney_comp_ratings.index.isin(X_season.index)].copy()\n",
    "tourney_games['predicted'] = preds_2018\n",
    "tourney_games.predicted = tourney_games['predicted'].apply(lambda x: map_zero_to_minus_one(x))\n",
    "tourney_games.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_1 = (tourney_games['seed_t'] > tourney_games['seed_o']) & (tourney_games['predicted'] == 1)\n",
    "cond_2 = (tourney_games['seed_t'] < tourney_games['seed_o']) & (tourney_games['predicted'] == -1)\n",
    "\n",
    "predictions_counter_seed = tourney_games[cond_1 | cond_2]\n",
    "predictions_counter_seed[['round','seed_t','team_t','seed_o','team_o','game_result','predicted','win_pts','lose_pts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct counter seed predictions\n",
    "correct_counter_predictions = predictions_counter_seed[predictions_counter_seed['game_result']== predictions_counter_seed['predicted']]\n",
    "correct_counter_predictions[['round','seed_t','team_t','seed_o','team_o','game_result','predicted','win_pts','lose_pts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrect counter seed predictions\n",
    "wrong_counter_predictions = predictions_counter_seed[predictions_counter_seed['game_result'] != predictions_counter_seed['predicted']]\n",
    "wrong_counter_predictions[['round','seed_t','team_t','seed_o','team_o','game_result','predicted','win_pts','lose_pts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of counter seed predictions= \", len(predictions_counter_seed.index))\n",
    "print(\"Number of correct counter seed predictions= \", len(correct_counter_predictions.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_result = utils.compute_log_loss(tourney_games['game_result'].values, np.array(t1_win_probabilities))\n",
    "log_loss_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
