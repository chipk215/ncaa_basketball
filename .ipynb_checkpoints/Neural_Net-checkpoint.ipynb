{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_feature_name_with_importance_value(features, importances):\n",
    "    \"\"\"\n",
    "    Join via a list of tuples, feature names with their importance values\n",
    "    :param features: data frame whose features are represented by columns used by classifier\n",
    "    :param importances: feature importance scores assigned by classifier\n",
    "    :return: sorted list (highest importances first) of feature,importance tuples\n",
    "    \"\"\"\n",
    "    if features.columns.shape[0] != importances.shape[0]:\n",
    "        return []\n",
    "\n",
    "    feature_importances = []\n",
    "    for item in range(features.columns.shape[0]):\n",
    "        feature_importances.append((features.columns[item], importances[item]))\n",
    "    feature_importances_sorted = sorted(feature_importances, reverse=True, key=lambda kv: kv[1])\n",
    "\n",
    "    return feature_importances_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records=  5149\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5149 entries, 0 to 5148\n",
      "Data columns (total 13 columns):\n",
      "points_game           5149 non-null float64\n",
      "field_goals_pct       5149 non-null float64\n",
      "offensive_rebounds    5149 non-null float64\n",
      "free_throws_att       5149 non-null float64\n",
      "free_throws_pct       5149 non-null float64\n",
      "turnovers             5149 non-null float64\n",
      "win_pct               5149 non-null float64\n",
      "game_id               5149 non-null object\n",
      "home_team             5149 non-null bool\n",
      "market                5149 non-null object\n",
      "opp_market            5149 non-null object\n",
      "game_result           5149 non-null object\n",
      "game_date             5149 non-null object\n",
      "dtypes: bool(1), float64(7), object(5)\n",
      "memory usage: 487.8+ KB\n"
     ]
    }
   ],
   "source": [
    "game_data = pd.read_csv('D1_2015_Processed_Stats.csv')\n",
    "print(\"Number of records= \", game_data.shape[0])\n",
    "game_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['points_game','field_goals_pct','offensive_rebounds','free_throws_att',\n",
    "                'free_throws_pct','turnovers','win_pct','home_team']\n",
    "\n",
    "X = game_data[features].copy()\n",
    "X = pd.get_dummies(X, columns=['home_team'], drop_first=True)\n",
    "y= game_data['game_result'].copy()\n",
    "y = pd.get_dummies(y, columns=['game_result'], drop_first=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model Score=  0.8497208060208788\n"
     ]
    }
   ],
   "source": [
    "tree_count =2000\n",
    "\n",
    "rf_classifier: RandomForestClassifier = RandomForestClassifier(tree_count, max_features='sqrt',\n",
    "                                                                   min_samples_split=10, min_samples_leaf=2,\n",
    "                                                                   max_depth=10, random_state=0)\n",
    "    \n",
    "rf_classifier.fit(X_train, y_train.WIN)\n",
    "score = rf_classifier.score(X_train, y_train.WIN)\n",
    "print(\"Training Model Score= \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF model accuracy is 0.70\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(\"RF model accuracy is %2.2f\" % metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('win_pct', 0.2513733464604651), ('field_goals_pct', 0.13558203317777684), ('points_game', 0.127475160163841), ('home_team_True', 0.12566089811824874), ('turnovers', 0.10228418263465966), ('offensive_rebounds', 0.10189260188621967), ('free_throws_pct', 0.0787294488348394), ('free_throws_att', 0.077002328723949)]\n"
     ]
    }
   ],
   "source": [
    "importances = rf_classifier.feature_importances_\n",
    "feature_importances = join_feature_name_with_importance_value(X_train, importances)\n",
    "print(feature_importances)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]}\n"
     ]
    }
   ],
   "source": [
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=100, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2,\n",
    "                               random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,  y_train.WIN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1800,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_depth': 10}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
